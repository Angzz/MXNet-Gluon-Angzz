{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 阿里服装属性标签识别\n",
    "\n",
    "<img src=\"https://work.alibaba-inc.com/aliwork_tfs/g01_alibaba-inc_com/tfscom/TB1Zja1Xb1YBuNjSszhXXcUsFXa.tfsprivate.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T11:08:17.289444Z",
     "start_time": "2018-04-07T11:08:17.277716Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from mxnet import nd\n",
    "from mxnet import image\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mlt\n",
    "mlt.rcParams['figure.dpi'] = 120\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T11:10:18.526095Z",
     "start_time": "2018-04-07T11:10:18.519611Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def mkdir_if_not_exist(path):\n",
    "    if not os.path.exists(os.path.join(*path)):\n",
    "        os.makedirs(os.path.join(*path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T11:10:51.847773Z",
     "start_time": "2018-04-07T11:10:51.843037Z"
    }
   },
   "outputs": [],
   "source": [
    "# mkdir_if_not_exist(['data/train_valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整理数据集为``gluon``的``ImageFolderDataset``支持的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'skirt_length_labels'\n",
    "\n",
    "warmup_label_dir = 'data/web/Annotations/skirt_length_labels.csv'\n",
    "base_label_dir = 'data/base/Annotations/label.csv'\n",
    "\n",
    "image_path = []\n",
    "\n",
    "with open(warmup_label_dir, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    tokens = [l.rstrip().split(',') for l in lines]\n",
    "    for path, _, label in tokens:\n",
    "        image_path.append(('data/web/' + path, label))\n",
    "\n",
    "with open(base_label_dir, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    tokens = [l.rstrip().split(',') for l in lines]\n",
    "    for path, _, label in tokens:\n",
    "        image_path.append(('data/base/' + path, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T11:29:25.715216Z",
     "start_time": "2018-04-07T11:29:25.709158Z"
    }
   },
   "source": [
    "画出图片，其中标签是若干个n和一个y组成的字符串，字母y出现的位置就是图片对应的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_path):\n",
    "    with open(img_path, 'rb') as f:\n",
    "        img = image.imdecode(f.read())\n",
    "    plt.imshow(img.asnumpy())\n",
    "    return img\n",
    "\n",
    "plot_image(img_path[0][0])\n",
    "print(\"Official Label String: %s\" % (image_path[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好训练集和测试集的目录，以及6个裙子类别对应的子目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_if_not_exist(['data/train_valid', task])\n",
    "mkdir_if_not_exist(['data/train_valid', task, 'train'])\n",
    "mkdir_if_not_exist(['data/train_valid', task, 'val'])\n",
    "m = len(list(image_path[0][1]))\n",
    "for mm in range(m):\n",
    "    mkdir_if_not_exist(['data/train_valid', task, 'train', str(mm)])\n",
    "    mkdir_if_not_exist(['data/train_valid', task, 'val', str(mm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机打乱训练集和测试集，并复复制图片到各自对应的目录中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "n = len(image_path)\n",
    "random.seed(1024)\n",
    "random.shuffle(image_path)\n",
    "train_count = 0\n",
    "\n",
    "for path, label in image_path:\n",
    "    label_index = list(labell).index('y')\n",
    "    if train_count < n * .9:\n",
    "        shutil.copy(path, os.path.join('data/train_valid', task, 'train', str(label_index)))\n",
    "    else:\n",
    "        shutil.copy(path, os.path.join('data/train_valid', task, 'val', str(label_index)))\n",
    "    train_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习\n",
    "* 使用ImageNet训练好的模型进行训练\n",
    "\n",
    "在ImageNet上训练的模型输出是1000维的，我们需要定义一个新的``resnet50_v2``网络，其中：\n",
    "* 输出层之前的权重是预训练好的\n",
    "* 输出是6维的，且输出层的权重随机初始化\n",
    "\n",
    "之后，我们可以根据具体的机器环境选择将网络保存在CPU或GPU上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T11:52:02.918851Z",
     "start_time": "2018-04-07T11:52:02.913659Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo import vision as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T11:52:58.269797Z",
     "start_time": "2018-04-07T11:52:57.900061Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_net = models.resnet50_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:39:44.756791Z",
     "start_time": "2018-04-07T12:39:44.751262Z"
    }
   },
   "outputs": [],
   "source": [
    "num_gpu = 0\n",
    "\n",
    "ctx = [mx.gpu(i) for i in range(num_gpu)] if num_gpu > 0 else [mx.cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:39:45.051729Z",
     "start_time": "2018-04-07T12:39:44.874317Z"
    }
   },
   "outputs": [],
   "source": [
    "finetune_net = models.resnet50_v2(classes=6)\n",
    "finetune_net.features = pretrained_net.features\n",
    "finetune_net.output.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "finetune_net.collect_params().reset_ctx(ctx)\n",
    "finetune_net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义评估与辅助函数\n",
    "* 计算Average Precision,官方的结果评价标准\n",
    "* 训练集与验证集的图片增广函数\n",
    "* 每轮训练结束后在测试集上的评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:14:02.855828Z",
     "start_time": "2018-04-07T12:14:02.844752Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_ap(labels, outputs):\n",
    "    cnt = 0\n",
    "    ap = 0.\n",
    "    for label, output in zip(labels, outputs):\n",
    "        for lb, op in zip(label.asnumpy().astype(np.int), output.asnumpy()):\n",
    "            op_argsort = np.argsort(op)[::-1]\n",
    "            lb_int = int(lb)\n",
    "            ap += 1.0 / (1 + list(op_argsort).index(lb_int))\n",
    "            cnt += 1\n",
    "    return ((ap, cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:19:58.225011Z",
     "start_time": "2018-04-07T12:19:58.202014Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_train(data, label):\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), resize=256, rand_crop=True, rand_mirror=True,\n",
    "                                   mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label].asscalar()))\n",
    "\n",
    "def transform_val(data, label):\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), resize=256, \n",
    "                                    mean=np.array([0.485, 0.456, 0.406]), \n",
    "                                    std=np.array([0.229, 0.224, 0.225]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label].asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:30:27.128792Z",
     "start_time": "2018-04-07T12:30:27.100935Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在验证集上训预测并评估\n",
    "def validate(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    L = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    AP = 0.\n",
    "    AP_cnt = 0\n",
    "    val_loss = 0\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], \n",
    "                                          ctx_list=ctx,\n",
    "                                          batch_axis=0,\n",
    "                                          even_split=False)\n",
    "        \n",
    "        label = gluon.utils.split_and_load(batch[1],\n",
    "                                          ctx_list=ctx,\n",
    "                                          batch_axis=0,\n",
    "                                          even_split=False)\n",
    "        \n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "        loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "        val_loss += sum([l.mean().asscalar() for l in loss]) / len(loss)\n",
    "        ap, cnt = calculate_ap(label, outputs)\n",
    "        AP += ap\n",
    "        AP_cnt += cnt \n",
    "    _, val_acc = metric.get()\n",
    "    return ((val_acc, AP / AP_cnt, val_loss / len(val_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迁移训练的一个特性是说我们一般认为整个网络的参数不需要进行很大地改动，因此我们的学习率一般都设为一个比较小的值，比如0.001。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:32:18.235308Z",
     "start_time": "2018-04-07T12:32:18.229592Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "wd = 1e-4\n",
    "epochs = 2\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:34:38.637411Z",
     "start_time": "2018-04-07T12:34:38.633103Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join('data/train_valid', task, 'train')\n",
    "val_path = os.path.join('data/train_valid', task, 'val')\n",
    "\n",
    "# 定义训练集的 DataLoader\n",
    "train_data = gluon.data.DataLoader(gluon.data.vision.ImageFolderDataset(train_path, transform=transform_train),\n",
    "                                  batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# 定义验证集的 DataLoader\n",
    "val_data = gluon.data.DataLoader(gluon.data.vision.ImageFolderDataset(val_path, transform=transform_val),\n",
    "                                batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:40:06.345541Z",
     "start_time": "2018-04-07T12:40:06.334734Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {'learning_rate':lr, 'momentum':momentum, 'wd':wd})\n",
    "\n",
    "# 定义准确率评估函数，损失函数\n",
    "L = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T12:41:02.929930Z",
     "start_time": "2018-04-07T12:41:02.924288Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time()\n",
    "    \n",
    "    train_loss = 0\n",
    "    metric.reset()\n",
    "    AP = 0.\n",
    "    AP_cnt = 0\n",
    "    \n",
    "    num_batch = len(train_index)\n",
    "    \n",
    "    for i, batch in enumerate(train_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLeNet V4 \n",
    "\n",
    "详细论文参考：[Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-V4 \n",
    "\n",
    "#### Inception-V4网络的架构：\n",
    "\n",
    "<img src=\"../img/Chapter4-Convolutional-Neural-Networks/4-18.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.653783Z",
     "start_time": "2018-01-29T15:50:17.729019Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "ctx = mx.cpu()\n",
    "\n",
    "import matplotlib as mlt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.664843Z",
     "start_time": "2018-01-29T15:50:18.658179Z"
    }
   },
   "outputs": [],
   "source": [
    "def BN_ReLU_Conv(channels, kernel_size, strides=1, padding=0):\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(\n",
    "            gluon.nn.BatchNorm(axis=1),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels, kernel_size=kernel_size, strides=strides, padding=padding)\n",
    "        ) \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.708090Z",
     "start_time": "2018-01-29T15:50:18.669584Z"
    }
   },
   "outputs": [],
   "source": [
    "def Stem(X):\n",
    "    # path1\n",
    "    b1 = gluon.nn.Sequential()\n",
    "    with b1.name_scope():\n",
    "        b1.add(  \n",
    "            BN_ReLU_Conv(32, kernel_size=3, strides=2),\n",
    "            BN_ReLU_Conv(32, kernel_size=3),\n",
    "            BN_ReLU_Conv(64, kernel_size=3, padding=1),        \n",
    "        ) \n",
    "    conv1 = BN_ReLU_Conv(96, kernel_size=3, strides=2)\n",
    "    maxp1 = gluon.nn.MaxPool2D(pool_size=2)\n",
    "    path1 = nd.concat(conv1(b1(X)), maxp1(b1(X)), dim=1)\n",
    "    \n",
    "    # path2 \n",
    "    b2 = gluon.nn.Sequential()\n",
    "    with b2.name_scope():\n",
    "        b2.add(\n",
    "            BN_ReLU_Conv(64, kernel_size=1),\n",
    "            BN_ReLU_Conv(96, kernel_size=3)\n",
    "        )\n",
    "    b3 = gluon.nn.Sequential()\n",
    "    with b3.name_scope():\n",
    "        b3.add(\n",
    "            BN_ReLU_Conv(64, kernel_size=1),\n",
    "            BN_ReLU_Conv(64, kernel_size=(7,1), padding=(3,0)),\n",
    "            BN_ReLU_Conv(64, kernel_size=(1,7), padding=(0,3)),\n",
    "            BN_ReLU_Conv(96, kernel_size=3)\n",
    "        )\n",
    "    path2 = nd.concat(b2(path1), b3(path1), dim=1)\n",
    "    \n",
    "    # path3\n",
    "    conv2 = BN_ReLU_Conv(192, kernel_size=3, strides=2)\n",
    "    maxp2 = gluon.nn.MaxPool2D(pool_size=2)\n",
    "    path3 = nd.concat(conv2(path2), maxp2(path2), dim=1)\n",
    "    \n",
    "    return path3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.783749Z",
     "start_time": "2018-01-29T15:50:18.713194Z"
    }
   },
   "outputs": [],
   "source": [
    "class Stem(gluon.Block):\n",
    "    def __init__(self, n1, n2, n3, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        # path1\n",
    "        self.b1 = gluon.nn.Sequential()\n",
    "        self.b1.add(  \n",
    "            BN_ReLU_Conv(n1[0], kernel_size=3, strides=2),\n",
    "            BN_ReLU_Conv(n1[1], kernel_size=3),\n",
    "            BN_ReLU_Conv(n1[2], kernel_size=3, padding=1),   \n",
    "        )\n",
    "        self.conv1 = BN_ReLU_Conv(n1[3], kernel_size=3, strides=2)\n",
    "        self.maxp1 = gluon.nn.MaxPool2D(pool_size=2)\n",
    "        \n",
    "        # path2\n",
    "        self.b2 = gluon.nn.Sequential()\n",
    "        self.b2.add(\n",
    "            BN_ReLU_Conv(n2[0][0], kernel_size=1),\n",
    "            BN_ReLU_Conv(n2[0][1], kernel_size=3)\n",
    "        )\n",
    "        self.b3 = gluon.nn.Sequential()\n",
    "        self.b3.add(\n",
    "            BN_ReLU_Conv(n2[1][0], kernel_size=1),\n",
    "            BN_ReLU_Conv(n2[1][1], kernel_size=(7,1), padding=(3,0)),\n",
    "            BN_ReLU_Conv(n2[1][2], kernel_size=(1,7), padding=(0,3)),\n",
    "            BN_ReLU_Conv(n2[1][3], kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        # path3\n",
    "        self.conv2 = BN_ReLU_Conv(n3, kernel_size=3, strides=2)\n",
    "        self.maxp2 = gluon.nn.MaxPool2D(pool_size=2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.b1(X)\n",
    "        p1 = nd.concat(self.conv1(p1), self.maxp1(p1), dim=1)\n",
    "        p2 = nd.concat(self.b2(p1), self.b3(p1), dim=1)\n",
    "        p3 = nd.concat(self.conv2(p2), self.maxp2(p2))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p_1 : \", p1.shape)\n",
    "            print(\"p_2 : \", p2.shape)\n",
    "            print(\"p_3 : \", p3.shape)\n",
    "            \n",
    "        return p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.792559Z",
     "start_time": "2018-01-29T15:50:18.789162Z"
    }
   },
   "outputs": [],
   "source": [
    "# X = nd.random.normal(shape=(1, 3, 299, 299), ctx=ctx)\n",
    "# stem = Stem([32, 32, 64, 96], [[64, 96], [64, 64, 64, 96]], 192, debug=True)\n",
    "# y = stem(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.843570Z",
     "start_time": "2018-01-29T15:50:18.797605Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception_A(gluon.Block):\n",
    "    def __init__(self, n1, n2, n3, n4, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        self.p1_1 = gluon.nn.AvgPool2D(pool_size=3, strides=1, padding=1)\n",
    "        self.p1_2 = BN_ReLU_Conv(n1, kernel_size=1)\n",
    "        self.p2_1 = BN_ReLU_Conv(n2, kernel_size=1)\n",
    "        self.p3_1 = BN_ReLU_Conv(n3[0], kernel_size=1)\n",
    "        self.p3_2 = BN_ReLU_Conv(n3[1], kernel_size=3, padding=1)\n",
    "        self.p4_1 = BN_ReLU_Conv(n4[0], kernel_size=1)\n",
    "        self.p4_2 = BN_ReLU_Conv(n4[1], kernel_size=3, padding=1)\n",
    "        self.p4_3 = BN_ReLU_Conv(n4[2], kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.p1_2(self.p1_1(X))\n",
    "        p2 = self.p2_1(X)\n",
    "        p3 = self.p3_2(self.p3_1(X))\n",
    "        p4 = self.p4_3(self.p4_2(self.p4_1(X)))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p_1 : \", p1.shape)\n",
    "            print(\"p_2 : \", p2.shape)\n",
    "            print(\"p_3 : \", p3.shape)\n",
    "            print(\"p_4 : \", p4.shape)\n",
    "            \n",
    "        out = nd.concat(p1, p2, p3, p4, dim=1)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.852482Z",
     "start_time": "2018-01-29T15:50:18.848855Z"
    }
   },
   "outputs": [],
   "source": [
    "# inception_a = Inception_A(96, 96, [64, 96], [64, 96, 96], debug=True)\n",
    "# X = nd.random.normal(shape=(1, 384, 35, 35), ctx=ctx)\n",
    "# y = inception_a(X)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.887236Z",
     "start_time": "2018-01-29T15:50:18.856601Z"
    }
   },
   "outputs": [],
   "source": [
    "class Reduction_A(gluon.Block):\n",
    "    def __init__(self, n2, n3, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        self.p1_1 = gluon.nn.MaxPool2D(pool_size=2)\n",
    "        self.p2_1 = BN_ReLU_Conv(n2, kernel_size=3, strides=2)\n",
    "        self.p3_1 = BN_ReLU_Conv(n3[0], kernel_size=1)\n",
    "        self.p3_2 = BN_ReLU_Conv(n3[1], kernel_size=3, padding=1)\n",
    "        self.p3_3 = BN_ReLU_Conv(n3[2], kernel_size=3, strides=2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.p1_1(X)\n",
    "        p2 = self.p2_1(X)\n",
    "        p3 = self.p3_3(self.p3_2(self.p3_1(X)))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p_1 : \", p1.shape)\n",
    "            print(\"p_2 : \", p2.shape)\n",
    "            print(\"p_3 : \", p3.shape)\n",
    "            \n",
    "        out = nd.concat(p1, p2, p3, dim=1)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.895957Z",
     "start_time": "2018-01-29T15:50:18.892562Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduction_a = Reduction_A(384, [192, 224, 256], debug=True) \n",
    "# X = nd.random.normal(shape=(1, 384, 35, 35), ctx=ctx)\n",
    "# y = reduction_a(X)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.962912Z",
     "start_time": "2018-01-29T15:50:18.900208Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception_B(gluon.Block):\n",
    "    def __init__(self, n1, n2, n3, n4, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        self.p1_1 = gluon.nn.AvgPool2D(pool_size=3, strides=1, padding=1)\n",
    "        self.p1_2 = BN_ReLU_Conv(n1, kernel_size=1)\n",
    "        self.p2_1 = BN_ReLU_Conv(n2, kernel_size=1)\n",
    "        self.p3_1 = BN_ReLU_Conv(n3[0], kernel_size=1)\n",
    "        self.p3_2 = BN_ReLU_Conv(n3[1], kernel_size=(1,7), padding=(0,3))\n",
    "        self.p3_3 = BN_ReLU_Conv(n3[2], kernel_size=(7,1), padding=(3,0))\n",
    "        self.p4_1 = BN_ReLU_Conv(n4[0], kernel_size=1)\n",
    "        self.p4_2 = BN_ReLU_Conv(n4[1], kernel_size=(1,7), padding=(0,3))\n",
    "        self.p4_3 = BN_ReLU_Conv(n4[2], kernel_size=(7,1), padding=(3,0))\n",
    "        self.p4_4 = BN_ReLU_Conv(n4[3], kernel_size=(1,7), padding=(0,3))\n",
    "        self.p4_5 = BN_ReLU_Conv(n4[4], kernel_size=(7,1), padding=(3,0))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.p1_2(self.p1_1(X))\n",
    "        p2 = self.p2_1(X)\n",
    "        p3 = self.p3_3(self.p3_2(self.p3_1(X)))\n",
    "        p4 = self.p4_5(self.p4_4(self.p4_3(self.p4_2(self.p4_1(X)))))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p_1 : \", p1.shape)\n",
    "            print(\"p_2 : \", p2.shape)\n",
    "            print(\"p_3 : \", p3.shape)\n",
    "            print(\"p_4 : \", p4.shape)\n",
    "            \n",
    "        out = nd.concat(p1, p2, p3, p4, dim=1)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:18.971603Z",
     "start_time": "2018-01-29T15:50:18.968192Z"
    }
   },
   "outputs": [],
   "source": [
    "# inception_b = Inception_B(128, 384, [192, 224, 256], [192, 192, 224, 224, 256], debug=True)\n",
    "# X = nd.random.normal(shape=(1, 1024, 17, 17), ctx=ctx)\n",
    "# y = inception_b(X)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:19.014411Z",
     "start_time": "2018-01-29T15:50:18.976443Z"
    }
   },
   "outputs": [],
   "source": [
    "class Reduction_B(gluon.Block):\n",
    "    def __init__(self, n2, n3, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        self.p1_1 = gluon.nn.MaxPool2D(pool_size=2)\n",
    "        self.p2_1 = BN_ReLU_Conv(n2[0], kernel_size=1)\n",
    "        self.p2_2 = BN_ReLU_Conv(n2[1], kernel_size=3, strides=2)\n",
    "        self.p3_1 = BN_ReLU_Conv(n3[0], kernel_size=1)\n",
    "        self.p3_2 = BN_ReLU_Conv(n3[1], kernel_size=(1,7), padding=(0,3))\n",
    "        self.p3_3 = BN_ReLU_Conv(n3[2], kernel_size=(7,1), padding=(3,0))\n",
    "        self.p3_4 = BN_ReLU_Conv(n3[3], kernel_size=3, strides=2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.p1_1(X)\n",
    "        p2 = self.p2_2(self.p2_1(X))\n",
    "        p3 = self.p3_4(self.p3_3(self.p3_2(self.p3_1(X))))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p_1 : \", p1.shape)\n",
    "            print(\"p_2 : \", p2.shape)\n",
    "            print(\"p_3 : \", p3.shape)\n",
    "            \n",
    "        out = nd.concat(p1, p2, p3, dim=1)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:19.023000Z",
     "start_time": "2018-01-29T15:50:19.019567Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduction_b = Reduction_B([192, 192], [256, 256, 320, 320], debug=True) \n",
    "# X = nd.random.normal(shape=(1, 1024, 17, 17), ctx=ctx)\n",
    "# y = reduction_b(X)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:19.097240Z",
     "start_time": "2018-01-29T15:50:19.027313Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception_C(gluon.Block):\n",
    "    def __init__(self, n1, n2, n3, n4, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        self.p1_1 = gluon.nn.AvgPool2D(pool_size=3, strides=1, padding=1)\n",
    "        self.p1_2 = BN_ReLU_Conv(n1, kernel_size=1)\n",
    "        self.p2_1 = BN_ReLU_Conv(n2, kernel_size=1)\n",
    "        self.p3_1 = BN_ReLU_Conv(n3[0], kernel_size=1)\n",
    "        self.p3_2 = BN_ReLU_Conv(n3[1], kernel_size=(1,3), padding=(0,1))\n",
    "        self.p3_3 = BN_ReLU_Conv(n3[2], kernel_size=(3,1), padding=(1,0))\n",
    "        self.p4_1 = BN_ReLU_Conv(n4[0], kernel_size=1)\n",
    "        self.p4_2 = BN_ReLU_Conv(n4[1], kernel_size=(1,3), padding=(0,1))\n",
    "        self.p4_3 = BN_ReLU_Conv(n4[2], kernel_size=(3,1), padding=(1,0))\n",
    "        self.p4_4 = BN_ReLU_Conv(n4[3], kernel_size=(1,3), padding=(0,1))\n",
    "        self.p4_5 = BN_ReLU_Conv(n4[4], kernel_size=(3,1), padding=(1,0))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.p1_2(self.p1_1(X))\n",
    "        p2 = self.p2_1(X)\n",
    "        p3 = self.p3_1(X)\n",
    "        p3 = nd.concat(self.p3_2(p3), self.p3_3(p3), dim=1)\n",
    "        p4 = self.p4_3(self.p4_2(self.p4_1(X)))\n",
    "        p4 = nd.concat(self.p4_4(p4), self.p4_5(p4), dim=1)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p_1 : \", p1.shape)\n",
    "            print(\"p_2 : \", p2.shape)\n",
    "            print(\"p_3 : \", p3.shape)\n",
    "            print(\"p_4 : \", p4.shape)\n",
    "            \n",
    "        out = nd.concat(p1, p2, p3, p4, dim=1)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:19.105882Z",
     "start_time": "2018-01-29T15:50:19.102511Z"
    }
   },
   "outputs": [],
   "source": [
    "# inception_c = Inception_C(256, 256, [384, 256, 256], [384, 448, 512, 256, 256], debug=True)\n",
    "# X = nd.random.normal(shape=(1, 1536, 8, 8), ctx=ctx)\n",
    "# y = inception_c(X)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:19.183053Z",
     "start_time": "2018-01-29T15:50:19.110243Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception_V4(gluon.Block):\n",
    "    def __init__(self, num_classes, verbose=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            b1 = gluon.nn.Sequential()\n",
    "            b1.add(Stem([32, 32, 64, 96], [[64, 96], [64, 64, 64, 96]], 192))\n",
    "            \n",
    "            b2 = gluon.nn.Sequential()\n",
    "            for i in range(4):\n",
    "                b2.add(Inception_A(96, 96, [64, 96], [64, 96, 96]))\n",
    "            b2.add(Reduction_A(384, [192, 224, 256]))   \n",
    "                \n",
    "            b3 = gluon.nn.Sequential()\n",
    "            for i in range(7):\n",
    "                b3.add(Inception_B(128, 384, [192, 224, 256], [192, 192, 224, 224, 256]))\n",
    "            b3.add(Reduction_B([192, 192], [256, 256, 320, 320]))\n",
    "            \n",
    "            b4 = gluon.nn.Sequential()\n",
    "            for i in range(3):\n",
    "                b4.add(Inception_C(256, 256, [384, 256, 256], [384, 448, 512, 256, 256]))\n",
    "                \n",
    "            b5 = gluon.nn.Sequential()\n",
    "            b5.add(\n",
    "                gluon.nn.AvgPool2D(pool_size=8),\n",
    "                gluon.nn.Dropout(0.2),\n",
    "            )\n",
    "            \n",
    "            b6 = gluon.nn.Sequential()\n",
    "            b6.add(\n",
    "                gluon.nn.Flatten(),\n",
    "                gluon.nn.Dense(num_classes)\n",
    "            )\n",
    "        self.net = gluon.nn.Sequential()\n",
    "        self.net.add(b1, b2, b3, b4, b5, b6)\n",
    "            \n",
    "    def forward(self, X):\n",
    "        out = X\n",
    "        for i, blk in enumerate(self.net):\n",
    "            out = blk(out)\n",
    "            if self.verbose:\n",
    "                print(\"blk %d : %s.\"% (i+1, out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.150438Z",
     "start_time": "2018-01-29T15:50:19.188102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blk 1 : (1, 384, 35, 35).\n",
      "blk 2 : (1, 1024, 17, 17).\n",
      "blk 3 : (1, 1536, 8, 8).\n",
      "blk 4 : (1, 1536, 8, 8).\n",
      "blk 5 : (1, 1536, 1, 1).\n",
      "blk 6 : (1, 10).\n"
     ]
    }
   ],
   "source": [
    "X = nd.random.normal(shape=(1, 3, 299, 299), ctx=ctx)\n",
    "inception_v4 = Inception_V4(10, verbose=True)\n",
    "inception_v4.initialize(ctx=ctx)\n",
    "y = inception_v4(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-ResNet-V1\n",
    "\n",
    "\n",
    "#### Inception-ResNet-V1以及Inception-ResNet-V2网络的架构：\n",
    "\n",
    "两个网络的区别是每个模块的架构不相同，以及输出的channels不同，但网络的整体结构是相同的,我们这里只实现V1版本\n",
    "\n",
    "<img src=\"../img/Chapter4-Convolutional-Neural-Networks/4-19.png\" width=\"320\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inception-ResNet定义的Stem模块：**\n",
    "\n",
    "<img src=\"../img/Chapter4-Convolutional-Neural-Networks/4-26.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inception-ResNet-A模块：**\n",
    "\n",
    "<img src=\"../img/Chapter4-Convolutional-Neural-Networks/4-27.png\" width=\"400\">\n",
    "\n",
    "**输出尺寸减半模块(Reduction-A):**\n",
    "\n",
    "<img src=\"../img/Chapter4-Convolutional-Neural-Networks/4-22.png\" width=\"400\">\n",
    "\n",
    "**Inception-ResNet-B模块：**\n",
    "\n",
    "<img src=\"../img/Chapter4-Convolutional-Neural-Networks/4-28.png\" width=\"300\">\n",
    "\n",
    "**输出尺寸减半模块(Reduction-B):**\n",
    "\n",
    "<img src=\"../img/Chapter4-Convolutional-Neural-Networks/4-30.png\" width=\"400\">\n",
    "\n",
    "**Inception-ResNet-C模块：**\n",
    "\n",
    "<img src=\"../img/Chapter4-Convolutional-Neural-Networks/4-29.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.167598Z",
     "start_time": "2018-01-29T15:50:20.155248Z"
    }
   },
   "outputs": [],
   "source": [
    "def CONV_BN_ReLU(channels, kernel_size, strides=1, padding=0):\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(\n",
    "            gluon.nn.Conv2D(channels, kernel_size=kernel_size, strides=strides, padding=padding),\n",
    "            gluon.nn.BatchNorm(axis=1),\n",
    "            gluon.nn.Activation('relu')\n",
    "        ) \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图14的Inception_ResNet_Stem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.199656Z",
     "start_time": "2018-01-29T15:50:20.172377Z"
    }
   },
   "outputs": [],
   "source": [
    "def Inception_ResNet_Stem(n1, n2, n3, n4, n5, n6):\n",
    "    stem = gluon.nn.Sequential()\n",
    "    with stem.name_scope():\n",
    "        stem.add(CONV_BN_ReLU(n1, kernel_size=3, strides=2))\n",
    "        stem.add(CONV_BN_ReLU(n2, kernel_size=3))\n",
    "        stem.add(CONV_BN_ReLU(n3, kernel_size=3, padding=1))\n",
    "        stem.add(gluon.nn.MaxPool2D(pool_size=2))\n",
    "        stem.add(CONV_BN_ReLU(n4, kernel_size=1))\n",
    "        stem.add(CONV_BN_ReLU(n5, kernel_size=3))\n",
    "        stem.add(CONV_BN_ReLU(n6, kernel_size=3, strides=2))\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.313289Z",
     "start_time": "2018-01-29T15:50:20.201106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 35, 35)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.random.normal(shape=(1, 3, 299, 299), ctx=ctx)\n",
    "stem = Inception_ResNet_Stem(32, 32, 64, 80, 192, 256)\n",
    "stem.initialize(ctx=ctx)\n",
    "y = stem(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图10的Inception-ResNet-A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.402665Z",
     "start_time": "2018-01-29T15:50:20.314687Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception_ResNet_A(gluon.Block):\n",
    "    def __init__(self, n1, n2, n3, n_concat, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        self.conv1 = CONV_BN_ReLU(n1, kernel_size=1)\n",
    "        \n",
    "        self.b1 = gluon.nn.Sequential()\n",
    "        self.b1.add(\n",
    "            CONV_BN_ReLU(n2[0], kernel_size=1),\n",
    "            CONV_BN_ReLU(n2[1], kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.b2 = gluon.nn.Sequential()\n",
    "        self.b2.add(\n",
    "            CONV_BN_ReLU(n3[0], kernel_size=1),\n",
    "            CONV_BN_ReLU(n3[1], kernel_size=3, padding=1),\n",
    "            CONV_BN_ReLU(n3[2], kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = CONV_BN_ReLU(n_concat, kernel_size=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.conv1(X)\n",
    "        p2 = self.b1(X)\n",
    "        p3 = self.b2(X)\n",
    "        residual = self.conv2(nd.concat(p1, p2, p3, dim=1))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p1 : \", p1.shape)\n",
    "            print(\"p2 : \", p2.shape)\n",
    "            print(\"p3 : \", p3.shape)\n",
    "            print(\"residul : \", residual.shape)\n",
    "        \n",
    "        return nd.relu(residual + X)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.477827Z",
     "start_time": "2018-01-29T15:50:20.407919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 :  (1, 32, 35, 35)\n",
      "p2 :  (1, 32, 35, 35)\n",
      "p3 :  (1, 64, 35, 35)\n",
      "residul :  (1, 256, 35, 35)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 256, 35, 35)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ira = Inception_ResNet_A(32, [32, 32], [32, 48, 64], n_concat=256, debug=True)\n",
    "ira.initialize(ctx=ctx)\n",
    "X = nd.random.normal(shape=(1, 256, 35, 35), ctx=ctx)\n",
    "y = ira(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图11的Inception-ResNet-B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.550718Z",
     "start_time": "2018-01-29T15:50:20.482417Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception_ResNet_B(gluon.Block):\n",
    "    def __init__(self, n1, n2, n_concat, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        self.conv1 = CONV_BN_ReLU(n1, kernel_size=1)\n",
    "        \n",
    "        self.b1 = gluon.nn.Sequential()\n",
    "        self.b1.add(\n",
    "            CONV_BN_ReLU(n2[0], kernel_size=1),\n",
    "            CONV_BN_ReLU(n2[1], kernel_size=(1,7), padding=(0,3)),\n",
    "            CONV_BN_ReLU(n2[2], kernel_size=(7,1), padding=(3,0))\n",
    "        )\n",
    "        \n",
    "        self.conv2 = CONV_BN_ReLU(n_concat, kernel_size=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.conv1(X)\n",
    "        p2 = self.b1(X)\n",
    "        residual = self.conv2(nd.concat(p1, p2, dim=1))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p1 : \", p1.shape)\n",
    "            print(\"p2 : \", p2.shape)\n",
    "            print(\"residul : \", residual.shape)\n",
    "        \n",
    "        return nd.relu(residual + X)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.610569Z",
     "start_time": "2018-01-29T15:50:20.552164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 :  (1, 128, 17, 17)\n",
      "p2 :  (1, 128, 17, 17)\n",
      "residul :  (1, 896, 17, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 896, 17, 17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irb = Inception_ResNet_B(128, [128, 128, 128], n_concat=896, debug=True)\n",
    "irb.initialize(ctx=ctx)\n",
    "X = nd.random.normal(shape=(1, 896, 17, 17), ctx=ctx)\n",
    "y = irb(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图12的Reduction-B**\n",
    "\n",
    "** Reduction-A的结构与上面是一样的，但是Reduction-B的结构是不一样的，所以重新写Reduction-B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.705357Z",
     "start_time": "2018-01-29T15:50:20.615237Z"
    }
   },
   "outputs": [],
   "source": [
    "class IR_Reduction_B(gluon.Block):\n",
    "    def __init__(self, n2, n3, n4, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug \n",
    "        self.p1_1 = gluon.nn.MaxPool2D(pool_size=2)\n",
    "        self.p2_1 = CONV_BN_ReLU(n2[0], kernel_size=1)\n",
    "        self.p2_2 = CONV_BN_ReLU(n2[1], kernel_size=3, strides=2)\n",
    "        self.p3_1 = CONV_BN_ReLU(n3[0], kernel_size=1)\n",
    "        self.p3_2 = CONV_BN_ReLU(n3[1], kernel_size=3, strides=2)\n",
    "        self.p4_1 = CONV_BN_ReLU(n4[0], kernel_size=1)\n",
    "        self.p4_2 = CONV_BN_ReLU(n4[1], kernel_size=3, padding=1)\n",
    "        self.p4_3 = CONV_BN_ReLU(n4[2], kernel_size=3, strides=2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.p1_1(X)\n",
    "        p2 = self.p2_2(self.p2_1(X))\n",
    "        p3 = self.p3_2(self.p3_1(X))\n",
    "        p4 = self.p4_3(self.p4_2(self.p4_1(X)))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p_1 : \", p1.shape)\n",
    "            print(\"p_2 : \", p2.shape)\n",
    "            print(\"p_3 : \", p3.shape)\n",
    "            print(\"p_4 : \", p4.shape)\n",
    "            \n",
    "        out = nd.concat(p1, p2, p3, p4, dim=1)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.782102Z",
     "start_time": "2018-01-29T15:50:20.712242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_1 :  (1, 896, 8, 8)\n",
      "p_2 :  (1, 384, 8, 8)\n",
      "p_3 :  (1, 256, 8, 8)\n",
      "p_4 :  (1, 256, 8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1792, 8, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_reduction_b = IR_Reduction_B([256, 384], [256, 256], [256, 256, 256], debug=True) \n",
    "ir_reduction_b.initialize(ctx=ctx)\n",
    "X = nd.random.normal(shape=(1, 896, 17, 17), ctx=ctx)\n",
    "y = ir_reduction_b(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 图13的Inception_ResNet_C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.851674Z",
     "start_time": "2018-01-29T15:50:20.790391Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception_ResNet_C(gluon.Block):\n",
    "    def __init__(self, n1, n2, n_concat, debug=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.debug = debug\n",
    "        self.conv1 = CONV_BN_ReLU(n1, kernel_size=1)\n",
    "        \n",
    "        self.b1 = gluon.nn.Sequential()\n",
    "        self.b1.add(\n",
    "            CONV_BN_ReLU(n2[0], kernel_size=1),\n",
    "            CONV_BN_ReLU(n2[1], kernel_size=(1,3), padding=(0,1)),\n",
    "            CONV_BN_ReLU(n2[2], kernel_size=(3,1), padding=(1,0))\n",
    "        )\n",
    "        \n",
    "        self.conv2 = CONV_BN_ReLU(n_concat, kernel_size=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p1 = self.conv1(X)\n",
    "        p2 = self.b1(X)\n",
    "        residual = self.conv2(nd.concat(p1, p2, dim=1))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"p1 : \", p1.shape)\n",
    "            print(\"p2 : \", p2.shape)\n",
    "            print(\"residul : \", residual.shape)\n",
    "        \n",
    "        return nd.relu(residual + X)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:20.913074Z",
     "start_time": "2018-01-29T15:50:20.857067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 :  (1, 192, 17, 17)\n",
      "p2 :  (1, 192, 17, 17)\n",
      "residul :  (1, 1792, 17, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1792, 17, 17)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irc = Inception_ResNet_C(192, [192, 192, 192], n_concat=1792, debug=True)\n",
    "irc.initialize(ctx=ctx)\n",
    "X = nd.random.normal(shape=(1, 1792, 17, 17), ctx=ctx)\n",
    "y = irc(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:21.061947Z",
     "start_time": "2018-01-29T15:50:20.917840Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception_ResNet_V1(gluon.Block):\n",
    "    def __init__(self, num_classes, verbose=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            b1 = gluon.nn.Sequential()\n",
    "            b1.add(Inception_ResNet_Stem(32, 32, 64, 80, 192, 256))\n",
    "            \n",
    "            b2 = gluon.nn.Sequential()\n",
    "            for i in range(5):\n",
    "                b2.add(Inception_ResNet_A(32, [32, 32], [32, 48, 64], n_concat=256))\n",
    "            b2.add(Reduction_A(384, [192, 192, 256]))   \n",
    "                \n",
    "            b3 = gluon.nn.Sequential()\n",
    "            for i in range(10):\n",
    "                b3.add(Inception_ResNet_B(128, [128, 128, 128], n_concat=896))\n",
    "            b3.add(IR_Reduction_B([256, 384], [256, 256], [256, 256, 256]))\n",
    "            \n",
    "            b4 = gluon.nn.Sequential()\n",
    "            for i in range(5):\n",
    "                b4.add(Inception_ResNet_C(192, [192, 192, 192], n_concat=1792))\n",
    "                \n",
    "            b5 = gluon.nn.Sequential()\n",
    "            b5.add(\n",
    "                gluon.nn.AvgPool2D(pool_size=8),\n",
    "                gluon.nn.Dropout(0.2),\n",
    "            )\n",
    "            \n",
    "            b6 = gluon.nn.Sequential()\n",
    "            b6.add(\n",
    "                gluon.nn.Flatten(),\n",
    "                gluon.nn.Dense(num_classes)\n",
    "            )\n",
    "        self.net = gluon.nn.Sequential()\n",
    "        self.net.add(b1, b2, b3, b4, b5, b6)\n",
    "            \n",
    "    def forward(self, X):\n",
    "        out = X\n",
    "        for i, blk in enumerate(self.net):\n",
    "            out = blk(out)\n",
    "            if self.verbose:\n",
    "                print(\"blk %d : %s.\"% (i+1, out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:50:21.967027Z",
     "start_time": "2018-01-29T15:50:21.067474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blk 1 : (1, 256, 35, 35).\n",
      "blk 2 : (1, 896, 17, 17).\n",
      "blk 3 : (1, 1792, 8, 8).\n",
      "blk 4 : (1, 1792, 8, 8).\n",
      "blk 5 : (1, 1792, 1, 1).\n",
      "blk 6 : (1, 10).\n"
     ]
    }
   ],
   "source": [
    "X = nd.random.normal(shape=(1, 3, 299, 299), ctx=ctx)\n",
    "inception_resnet_v1 = Inception_ResNet_V1(10, verbose=True)\n",
    "inception_resnet_v1.initialize(ctx=ctx)\n",
    "y = inception_resnet_v1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:53:14.619214Z",
     "start_time": "2018-01-29T15:53:14.597451Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "from time import time\n",
    "\n",
    "inception_resnet_v1 = inception_resnet_v1(10, verbose=False)\n",
    "inception_resnet_v1.initialize(ctx=ctx)\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = .1\n",
    "trainer = gluon.Trainer(inception_resnet_v1.collect_params(), 'Adam', {'learning_rate': learning_rate})\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "batch_size = 64\n",
    "train_data, test_data = utils.load_dataset(batch_size, resize=299, data_type='cifar10')\n",
    "\n",
    "niter = 0\n",
    "moving_loss = .0\n",
    "smoothing_constant = .9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data, label in train_data:\n",
    "        with autograd.record():\n",
    "            output = inception_resnet_v1(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        niter += 1\n",
    "        curr_loss = nd.mean(loss).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

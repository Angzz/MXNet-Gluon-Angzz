{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用``gluon``实现卷积神经网络\n",
    "\n",
    "使用``gluon``实现一个简单的CNN与从零实现其实并没有太多的区别，但是，使用``gluon``时计算会快很多，这是因为``gluon``会调用底层使用C++优化过的计算图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:25:05.025310Z",
     "start_time": "2018-01-19T12:25:04.910173Z"
    }
   },
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:42.593895Z",
     "start_time": "2018-01-19T12:57:42.094207Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "import utils\n",
    "\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:42.898546Z",
     "start_time": "2018-01-19T12:57:42.594986Z"
    }
   },
   "outputs": [],
   "source": [
    "num_examples = 60000\n",
    "num_outputs = 10\n",
    "num_inputs = 784\n",
    "\n",
    "batch_size = 64\n",
    "train_data, test_data = utils.load_dataset(batch_size, data_type='mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:42.911837Z",
     "start_time": "2018-01-19T12:57:42.899788Z"
    }
   },
   "outputs": [],
   "source": [
    "num_filter_conv1 = 20\n",
    "num_filter_conv2 = 50\n",
    "num_fc1 = 512\n",
    "num_fc2 = num_outputs\n",
    "\n",
    "def get_net():\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        ############### Conv Layer ###############\n",
    "        net.add(gluon.nn.Conv2D(channels=20, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "        net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, strides=(1,1), activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "        ############### FC Layer ###############\n",
    "        net.add(gluon.nn.Dense(num_fc1, activation='relu'))\n",
    "        net.add(gluon.nn.Dense(num_fc2, activation='relu'))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:43.711844Z",
     "start_time": "2018-01-19T12:57:42.913056Z"
    }
   },
   "outputs": [],
   "source": [
    "net = get_net()\n",
    "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:43.721455Z",
     "start_time": "2018-01-19T12:57:43.713411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter sequential0_conv0_weight (shape=(20, 0, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv0_bias (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv1_weight (shape=(50, 0, 5, 5), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv1_bias (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense0_weight (shape=(512, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense0_bias (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense1_weight (shape=(10, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense1_bias (shape=(10,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:43.985679Z",
     "start_time": "2018-01-19T12:57:43.722736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data, _ in train_data:\n",
    "    data = data.as_in_context(ctx)\n",
    "    break\n",
    "    \n",
    "net(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:43.990459Z",
     "start_time": "2018-01-19T12:57:43.987753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter sequential0_conv0_weight (shape=(20, 1, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv0_bias (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv1_weight (shape=(50, 20, 5, 5), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv1_bias (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense0_weight (shape=(512, 800), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense0_bias (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense1_weight (shape=(10, 512), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense1_bias (shape=(10,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:43.995410Z",
     "start_time": "2018-01-19T12:57:43.991500Z"
    }
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T12:57:44.001667Z",
     "start_time": "2018-01-19T12:57:43.996423Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': learning_rate})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T13:01:53.415307Z",
     "start_time": "2018-01-19T12:57:44.002934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Moving Avg Loss 0.317980416602, Train acc 0.87735, Test acc 0.8807\n",
      "Epoch 1, Train Moving Avg Loss 0.0715107289863, Train acc 0.985216666667, Test acc 0.9835\n",
      "Epoch 2, Train Moving Avg Loss 0.0510586454028, Train acc 0.98855, Test acc 0.9866\n",
      "Epoch 3, Train Moving Avg Loss 0.041884068308, Train acc 0.992616666667, Test acc 0.9891\n",
      "Epoch 4, Train Moving Avg Loss 0.0270648670209, Train acc 0.99345, Test acc 0.987\n",
      "Epoch 5, Train Moving Avg Loss 0.0136126880306, Train acc 0.994833333333, Test acc 0.9889\n",
      "Epoch 6, Train Moving Avg Loss 0.0283742334714, Train acc 0.994133333333, Test acc 0.9871\n",
      "Epoch 7, Train Moving Avg Loss 0.0210650549476, Train acc 0.995766666667, Test acc 0.9881\n",
      "Epoch 8, Train Moving Avg Loss 0.00841941742711, Train acc 0.9978, Test acc 0.9906\n",
      "Epoch 9, Train Moving Avg Loss 0.00667158403, Train acc 0.997466666667, Test acc 0.9902\n"
     ]
    }
   ],
   "source": [
    "# 可以通过减少epochs的次数来设置early stop\n",
    "# 由loss可知，在epoch 5的时候，就可以停止训练了\n",
    "epochs = 10\n",
    "\n",
    "niter = 0\n",
    "moving_loss = .0\n",
    "smoothing_constant = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "        \n",
    "        ## moving loss\n",
    "        niter += 1\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss\n",
    "        ## 偏差修正\n",
    "        estimated_loss = moving_loss / (1- (1-smoothing_constant)**niter)\n",
    "        \n",
    "    train_acc = utils.evaluate_accuracy_gluon(train_data, net, ctx)\n",
    "    test_acc = utils.evaluate_accuracy_gluon(test_data, net, ctx)\n",
    "    print(\"Epoch %s, Train Moving Avg Loss %s, Train acc %s, Test acc %s\"\n",
    "         % (epoch, estimated_loss, train_acc, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Result For CIFAR10\n",
    "* 将各个阶段得到的网络进行集成学习，得到最终结果\n",
    "\n",
    "**截止到2018年3月5日，融合的模型有：**\n",
    "* Resnet200v2: bottleneck(erase first relu), add last bn.\n",
    "* Resnet164v2: bottleneck(erase first relu), add last bn.\n",
    "* Sparsenet100: growth_rate=36, bottleneck(erase_first_relu), add_last_bn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:33.333639Z",
     "start_time": "2018-03-02T02:53:32.507639Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:34.966639Z",
     "start_time": "2018-03-02T02:53:34.961639Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/kaggle_cifar10'\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "input_dir = 'train_valid_test'\n",
    "label_file = 'trainLabels.csv'\n",
    "valid_ratio = .1\n",
    "input_str = data_dir + '/' + input_dir + '/'\n",
    "model_dir = 'models'\n",
    "model_result_dir = 'model_result'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T05:02:42.987639Z",
     "start_time": "2018-03-02T05:02:38.791639Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_train(data, label):\n",
    "    im = data.astype('float32') / 255\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    im = nd.expand_dims(im, axis=0)\n",
    "    im = nd.pad(im, pad_width=(0,0,0,0,4,4,4,4), mode='constant', constant_value=0)[0]\n",
    "    im = nd.transpose(im, (1,2,0))\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 32, 32), resize=0,\n",
    "                        rand_crop=True, rand_resize=False, rand_mirror=True,\n",
    "                        mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                        std=np.array([0.2023, 0.1994, 0.2010]),\n",
    "                        brightness=0, contrast=0,\n",
    "                        saturation=0, hue=0,\n",
    "                        pca_noise=0, rand_gray=0, inter_method=2)\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
    "\n",
    "def transform_test(data, label):\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 32, 32),\n",
    "                        mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                        std=np.array([0.2023, 0.1994, 0.2010]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
    "\n",
    "train_valid_ds = gluon.data.vision.ImageFolderDataset(input_str + 'train_valid', transform=transform_train)\n",
    "test_ds = gluon.data.vision.ImageFolderDataset(input_str + 'test', transform=transform_test)\n",
    "test_data = gluon.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T03:05:01.854639Z",
     "start_time": "2018-03-02T03:05:01.845639Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_results(net, model_name, ctx=mx.gpu()):\n",
    "    num_test = 300000\n",
    "    net.load_params(os.path.join(data_dir, model_dir, model_name), ctx=ctx)\n",
    "    outputs = nd.zeros(shape=(num_test, 10), ctx=ctx)\n",
    "    for i, (data, _) in enumerate(tqdm(test_data)):\n",
    "        output = net(data.as_in_context(ctx))\n",
    "        outputs[i*batch_size:min((i+1)*batch_size, num_test), :] = output\n",
    "        nd.waitall()\n",
    "    nd.save(os.path.join(data_dir, model_result_dir, 'output_{}.nd'.format(model_name[:-7])), outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T03:05:02.726639Z",
     "start_time": "2018-03-02T03:05:02.718639Z"
    }
   },
   "outputs": [],
   "source": [
    "def ensemble_model_result(preds, weight_list=None):\n",
    "    if weight_list is None:\n",
    "        weight_list = [1, ] * len(preds)\n",
    "    output = nd.softmax(data=preds[0], axis=1) * weight_list[0]\n",
    "    for i in range(1, len(preds)):\n",
    "        output = output + nd.softmax(data=preds[i], axis=1) * weight_list[i]\n",
    "    preds = nd.argmax(data=output, axis=1).astype(int).asnumpy() % 10\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T03:05:04.049639Z",
     "start_time": "2018-03-02T03:05:04.045639Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list = ['cifar10-resnet200v2-bn-0.95490.params', 'cifar10-sparsenet_depth_100_growthrate_36_bn-0.95480.params', \n",
    "              'cifar10-resnet164v2-bn-0.95570.params']\n",
    "model_name_list = [model_name[:-7] for model_name in model_list]\n",
    "weight_list = [0.95490, 0.95480, 0.95570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T03:19:20.030639Z",
     "start_time": "2018-03-02T03:05:50.010639Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2344/2344 [13:28<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import modellib\n",
    "\n",
    "sparsenet = modellib.SparseNet(num_classes=10, num_sparseblk_count=3, depth=100, growth_rate=36, \n",
    "                      bottleneck=True, verbose=True)\n",
    "if not os.path.exists(os.path.join(data_dir, model_result_dir, 'output_{}.nd'.format(model_name_list[1]))):\n",
    "    save_model_results(sparsenet, model_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T03:33:32.094639Z",
     "start_time": "2018-03-02T03:20:47.262639Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2344/2344 [12:44<00:00,  3.07it/s]\n"
     ]
    }
   ],
   "source": [
    "depth = 200\n",
    "unit_list = [22, 22, 22]\n",
    "filter_list = [16, 64, 128, 256]\n",
    "resnet = modellib.ResNet(unit_list=unit_list, filter_list=filter_list, num_classes=10, \n",
    "                data_type='cifar10', bottle_neck=True, debug=True)\n",
    "if not os.path.exists(os.path.join(data_dir, model_result_dir, 'output_{}.nd'.format(model_name_list[0]))):\n",
    "    save_model_results(resnet, model_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 164\n",
    "unit_list = [18, 18, 18]\n",
    "filter_list = [16, 64, 128, 256]\n",
    "resnet = modellib.ResNet(unit_list=unit_list, filter_list=filter_list, num_classes=10, \n",
    "                data_type='cifar10', bottle_neck=True, debug=True)\n",
    "if not os.path.exists(os.path.join(data_dir, model_result_dir, 'output_{}.nd'.format(model_name_list[2]))):\n",
    "    save_model_results(resnet, model_list[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T05:03:01.450639Z",
     "start_time": "2018-03-02T05:03:00.378639Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for model_result in os.listdir(os.path.join(data_dir, model_result_dir)):\n",
    "    pred = nd.load(os.path.join(data_dir, model_result_dir, model_result))\n",
    "    preds.append(pred[0])\n",
    "    \n",
    "final_prediction = ensemble_model_result(preds, weight_list)\n",
    "sorted_ids = list(range(1, len(test_ds) + 1))\n",
    "sorted_ids.sort(key = lambda x:str(x))\n",
    "\n",
    "df = pd.DataFrame({'id': sorted_ids, 'label': final_prediction})\n",
    "df['label'] = df['label'].apply(lambda x: train_valid_ds.synsets[x])\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

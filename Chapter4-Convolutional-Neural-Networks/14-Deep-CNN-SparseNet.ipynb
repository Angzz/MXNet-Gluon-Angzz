{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsely Connected Convolutional Networks\n",
    "\n",
    "\n",
    "## 基本结构\n",
    "\n",
    "<img src=\"https://github.com/titu1994/keras-SparseNet/blob/master/images/sparse_connectivity.PNG?raw=true\" width=\"700\">\n",
    "\n",
    "## 与DenseNet的不同\n",
    "\n",
    "<img src=\"https://github.com/titu1994/keras-SparseNet/raw/master/images/dense_vs_sparse.png?raw=true\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018年1月30日前的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:41:00.395405Z",
     "start_time": "2018-02-27T04:40:59.934162Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T06:47:46.024757Z",
     "start_time": "2018-02-11T06:47:46.018139Z"
    }
   },
   "outputs": [],
   "source": [
    "def BN_ReLU_CONV(channels, kernel_size, strides=1, padding=0):\n",
    "    basic = gluon.nn.HybridSequential()\n",
    "    with basic.name_scope():\n",
    "        basic.add(\n",
    "            gluon.nn.BatchNorm(axis=1),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels, kernel_size=kernel_size, \n",
    "                            strides=strides, padding=padding)\n",
    "        )\n",
    "    return basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T10:09:42.107989Z",
     "start_time": "2018-02-11T10:09:42.085920Z"
    }
   },
   "outputs": [],
   "source": [
    "class SparseUnit(gluon.HybridBlock):\n",
    "    def __init__(self, channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # bottleneck unit\n",
    "        self.unit = gluon.nn.HybridSequential()\n",
    "        self.unit.add(\n",
    "            BN_ReLU_CONV(channels, kernel_size=1),\n",
    "            BN_ReLU_CONV(channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "            \n",
    "    def hybrid_forward(self, F, X):\n",
    "        return self.unit(X)\n",
    "    \n",
    "'''\n",
    "第二种方法\n",
    "'''\n",
    "class SparseUnit(gluon.nn.HybridBlock):\n",
    "    def __init__(self, channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.bn1 = gluon.nn.BatchNorm(axis=1)\n",
    "            self.conv1 = gluon.nn.Conv2D(channels, kernel_size=1)\n",
    "            self.bn2 = gluon.nn.BatchNorm(axis=1)\n",
    "            self.conv2 = gluon.nn.Conv2D(channels, kernel_size=3, padding=1)\n",
    "            \n",
    "    def hybrid_forward(self, F, X):\n",
    "        output = self.conv1(F.relu(self.bn1(X)))\n",
    "        return  self.conv2(F.relu(self.bn2(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T10:09:44.140689Z",
     "start_time": "2018-02-11T10:09:44.109575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000, 32, 32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SparseUnit(1000)\n",
    "s.initialize()\n",
    "s.hybridize()\n",
    "X = nd.random.normal(shape=(1,3,32,32))\n",
    "s(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T10:09:46.365308Z",
     "start_time": "2018-02-11T10:09:46.357240Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_index_fetch(x_list):\n",
    "    count = len(x_list)\n",
    "    i = 1\n",
    "    inputs = []\n",
    "    while i <= count:\n",
    "        inputs.append(x_list[count - i])\n",
    "        i *= 2\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T10:38:50.268290Z",
     "start_time": "2018-02-11T10:38:50.032444Z"
    }
   },
   "outputs": [],
   "source": [
    "class SparseBlock(gluon.nn.HybridBlock):\n",
    "    def __init__(self, layers, growth_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layers = layers\n",
    "        net = self.net = gluon.nn.HybridSequential()\n",
    "        for i in range(layers):\n",
    "            net.add(SparseUnit(growth_rate))\n",
    "        \n",
    "    def hybrid_forward(self, F, X):\n",
    "        X_list = [X]\n",
    "        for i, blk in enumerate(self.net):\n",
    "            X = blk(X)\n",
    "            X_list.append(X)\n",
    "            fetch_output = exponential_index_fetch(X_list)\n",
    "            tmp = fetch_output[0]\n",
    "            for out in fetch_output[1:]:\n",
    "                tmp = F.concat(tmp, out, dim=1)\n",
    "            X = tmp\n",
    "        # print(X.shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T10:23:28.647545Z",
     "start_time": "2018-02-11T10:23:28.515669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "blk = SparseBlock(12, 24)\n",
    "blk.collect_params().initialize()\n",
    "# blk.hybridize()\n",
    "X = nd.random.normal(shape=(1,16,32,32))\n",
    "print(blk(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T10:10:11.676690Z",
     "start_time": "2018-02-11T10:10:11.669437Z"
    }
   },
   "outputs": [],
   "source": [
    "def TransitionLayer(channels):\n",
    "    layer = gluon.nn.HybridSequential()\n",
    "    with layer.name_scope():\n",
    "        layer.add(\n",
    "            BN_ReLU_CONV(channels, kernel_size=1),\n",
    "            gluon.nn.AvgPool2D(pool_size=2)\n",
    "        )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T10:38:54.207856Z",
     "start_time": "2018-02-11T10:38:54.134416Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "BN_ReLU_CONV: 非线性单元\n",
    "'''\n",
    "def BN_ReLU_CONV(channels, kernel_size, strides=1, padding=0):\n",
    "    basic = gluon.nn.HybridSequential()\n",
    "    with basic.name_scope():\n",
    "        basic.add(\n",
    "            gluon.nn.BatchNorm(axis=1),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels, kernel_size=kernel_size, \n",
    "                            strides=strides, padding=padding)\n",
    "        )\n",
    "    return basic\n",
    "\n",
    "\n",
    "'''\n",
    "SparseUnit: Sparse单元\n",
    "'''\n",
    "class SparseUnit(gluon.HybridBlock):\n",
    "    def __init__(self, channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # bottleneck unit\n",
    "        self.unit = gluon.nn.HybridSequential()\n",
    "        self.unit.add(\n",
    "            BN_ReLU_CONV(channels, kernel_size=1),\n",
    "            BN_ReLU_CONV(channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "            \n",
    "    def hybrid_forward(self, F, X):\n",
    "        return self.unit(X)\n",
    "\n",
    "def exponential_index_fetch(x_list):\n",
    "    count = len(x_list)\n",
    "    i = 1\n",
    "    inputs = []\n",
    "    while i <= count:\n",
    "        inputs.append(x_list[count - i])\n",
    "        i *= 2\n",
    "    return inputs\n",
    "\n",
    "'''\n",
    "SparseBlock: Sparse连接层\n",
    "'''\n",
    "class SparseBlock(gluon.HybridBlock):\n",
    "    def __init__(self, layers, growth_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layers = layers\n",
    "        net = self.net = gluon.nn.HybridSequential()\n",
    "        for i in range(layers):\n",
    "            net.add(SparseUnit(growth_rate))\n",
    "        \n",
    "    def hybrid_forward(self, F, X):\n",
    "        X_list = [X]\n",
    "        for i, blk in enumerate(self.net):\n",
    "            X = blk(X)\n",
    "            X_list.append(X)\n",
    "            fetch_output = exponential_index_fetch(X_list)\n",
    "            tmp = fetch_output[0]\n",
    "            for out in fetch_output[1:]:\n",
    "                tmp = F.concat(tmp, out, dim=1)\n",
    "            X = tmp\n",
    "        # print(X.shape)\n",
    "        return X\n",
    "\n",
    "'''\n",
    "TransitionLayer: 过渡层\n",
    "'''\n",
    "def TransitionLayer(channels):\n",
    "    layer = gluon.nn.HybridSequential()\n",
    "    with layer.name_scope():\n",
    "        layer.add(\n",
    "            BN_ReLU_CONV(channels, kernel_size=1),\n",
    "            gluon.nn.AvgPool2D(pool_size=2)\n",
    "        )\n",
    "    return layer\n",
    "\n",
    "'''\n",
    "num_classes: 类别数\n",
    "num_sparseblk_count: 共有几个SparseBlock\n",
    "num_layers: 每个SparseBlock的层数\n",
    "growth_rate: 每个SparseBlock的输出通道数\n",
    "init_channels: Init Conv Layer的初始通道数\n",
    "verbose: 打印调试信息\n",
    "'''\n",
    "class SparseNet(gluon.HybridBlock):\n",
    "    def __init__(self, num_classes, num_sparseblk_count, num_layers, growth_rate=12, \n",
    "                 init_channels=16, verbose=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        net = self.net = gluon.nn.HybridSequential() # 整合之后的网络\n",
    "        with self.name_scope(): \n",
    "            \n",
    "            # Init Conv Layer\n",
    "            b1 = gluon.nn.HybridSequential()\n",
    "            b1.add(BN_ReLU_CONV(init_channels, kernel_size=3, padding=1))\n",
    "            net.add(b1)\n",
    "            \n",
    "            # Sparse Connected Layer\n",
    "            sparse_output_channel = init_channels\n",
    "            for i in range(num_sparseblk_count):\n",
    "                b2 = gluon.nn.HybridSequential()\n",
    "                \n",
    "                # Adding SparseBlock\n",
    "                b2.add(SparseBlock(num_layers, growth_rate))\n",
    "                \n",
    "                # 统计sparsenet的输出通道数 用于给过渡层减半\n",
    "                sparse_filter = [sparse_output_channel]\n",
    "                for _ in range(num_layers):\n",
    "                    sparse_filter.append(growth_rate)\n",
    "                sparse_output_channel = sum(exponential_index_fetch(sparse_filter)) // 2\n",
    "                \n",
    "                #过渡层比SparseBlock层少一层 \n",
    "                if i != num_sparseblk_count-1:\n",
    "                    # Transition Layer 每次过渡层将输出通道减半\n",
    "                    b2.add(TransitionLayer(sparse_output_channel))\n",
    "                net.add(b2)\n",
    "                    \n",
    "            # Classification Layer\n",
    "            b3 = gluon.nn.HybridSequential()\n",
    "            b3.add(\n",
    "                gluon.nn.GlobalAvgPool2D(),\n",
    "                gluon.nn.Dense(num_classes)\n",
    "            )\n",
    "            net.add(b3)\n",
    "            \n",
    "    def hybrid_forward(self, F, X):\n",
    "        out = X\n",
    "        for i, blk in enumerate(self.net):\n",
    "            out = blk(out)\n",
    "            # if self.verbose:\n",
    "                # print(\"blk %d : %s\" % (i+1, out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-11T10:39:06.680087Z",
     "start_time": "2018-02-11T10:39:06.388938Z"
    }
   },
   "outputs": [],
   "source": [
    "sparsenet = SparseNet(num_classes=10, num_sparseblk_count=3, num_layers=12, \n",
    "                      growth_rate=24, init_channels=16, verbose=True)\n",
    "sparsenet.initialize()\n",
    "sparsenet.hybridize()\n",
    "X = nd.random.uniform(shape=(1,3,32,32))\n",
    "y = sparsenet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最新版本(2018年2月20日)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:41:04.358244Z",
     "start_time": "2018-02-27T04:41:03.715242Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "BN_ReLU_CONV: 非线性单元\n",
    "'''\n",
    "def BN_ReLU_CONV(channels, kernel_size, strides=1, padding=0, erase_relu=False):\n",
    "    basic = gluon.nn.HybridSequential()\n",
    "    with basic.name_scope():\n",
    "        basic.add(gluon.nn.BatchNorm(axis=1, epsilon=2e-5))\n",
    "        if not erase_relu:\n",
    "            basic.add(gluon.nn.Activation('relu'))\n",
    "        basic.add(gluon.nn.Conv2D(channels, kernel_size=kernel_size, \n",
    "                                  strides=strides, padding=padding)) \n",
    "    return basic\n",
    "\n",
    "\n",
    "'''\n",
    "SparseUnit: Sparse单元\n",
    "'''\n",
    "class SparseUnit(gluon.HybridBlock):\n",
    "    def __init__(self, channels, bottleneck=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # bottleneck unit\n",
    "        self.bottleneck = bottleneck\n",
    "        with self.name_scope():\n",
    "            unit = self.unit = gluon.nn.HybridSequential()\n",
    "            if self.bottleneck:\n",
    "                unit.add(BN_ReLU_CONV(channels, kernel_size=1))\n",
    "            unit.add(BN_ReLU_CONV(channels, kernel_size=3, padding=1))\n",
    "            \n",
    "    def hybrid_forward(self, F, X):\n",
    "        return self.unit(X)\n",
    "\n",
    "'''\n",
    "fetch_exponential_idx: 返回列表中的2^k的index\n",
    "'''\n",
    "def fetch_exponential_idx(x_list):\n",
    "    count = len(x_list)\n",
    "    i = 1    \n",
    "    inputs = []\n",
    "    while i <= count:\n",
    "        inputs.append(x_list[count - i])\n",
    "        i *= 2\n",
    "    return inputs\n",
    "\n",
    "'''\n",
    "SparseBlock: Sparse block层\n",
    "'''\n",
    "class SparseBlock(gluon.HybridBlock):\n",
    "    def __init__(self, nDenseBlock, growth_rate, bottleneck=False, droprate=.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.nDenseBlock = nDenseBlock\n",
    "        with self.name_scope():\n",
    "            net = self.net = gluon.nn.HybridSequential()\n",
    "            for i in range(nDenseBlock):\n",
    "                blk = gluon.nn.HybridSequential()\n",
    "                if bottleneck:\n",
    "                    interchannels = 4 * growth_rate\n",
    "                    blk.add(BN_ReLU_CONV(interchannels, kernel_size=1, erase_relu=True))\n",
    "                    if droprate > .0:\n",
    "                        blk.add(gluon.nn.Dropout(droprate)) \n",
    "                    blk.add(BN_ReLU_CONV(growth_rate, kernel_size=3, padding=1))\n",
    "                    if droprate > .0:\n",
    "                        blk.add(gluon.nn.Dropout(droprate)) \n",
    "                else:\n",
    "                    blk.add(BN_ReLU_CONV(growth_rate, kernel_size=3, padding=1))\n",
    "                    if droprate > .0:\n",
    "                        blk.add(gluon.nn.Dropout(droprate)) \n",
    "                # add BN layer each\n",
    "                blk.add(gluon.nn.BatchNorm(axis=1, epsilon=2e-5))\n",
    "                net.add(blk)\n",
    "        \n",
    "    def hybrid_forward(self, F, X):\n",
    "        X_list = [X]\n",
    "        for i, blk in enumerate(self.net):\n",
    "            X = blk(X)\n",
    "            X_list.append(X)\n",
    "            expidx_output = fetch_exponential_idx(X_list)\n",
    "            \n",
    "            # concat\n",
    "            tmp = expidx_output[0] \n",
    "            for out in expidx_output[1:]:\n",
    "                tmp = F.concat(tmp, out, dim=1)\n",
    "            X = tmp\n",
    "        print('SparseBlk - ', X.shape)\n",
    "        return X\n",
    "\n",
    "'''\n",
    "TransitionLayer: 过渡层\n",
    "'''\n",
    "def TransitionLayer(channels, droprate=0.0):\n",
    "    layer = gluon.nn.HybridSequential()\n",
    "    with layer.name_scope():\n",
    "        layer.add(BN_ReLU_CONV(channels, kernel_size=1))\n",
    "        if droprate > 0.0:\n",
    "            layer.add(gluon.nn.Dropout(droprate))\n",
    "        layer.add(gluon.nn.AvgPool2D(pool_size=2, strides=2))\n",
    "    return layer\n",
    "\n",
    "'''\n",
    "num_classes: 待预测的类别数\n",
    "num_sparseblk_count: 共需要加入几个SparseBlock\n",
    "depth: 网络总的层数\n",
    "reduction: transitionlayer的输出通道数减少比例\n",
    "droprate: transitionlayer的dropout层的丢弃比例\n",
    "growth_rate: 每个SparseBlock的固定输出通道数\n",
    "init_channels: Init Conv Layer的初始输出通道数\n",
    "bottleneck: 是否为bottleneck\n",
    "verbose: 打印调试信息\n",
    "'''\n",
    "class SparseNet(gluon.HybridBlock):\n",
    "    def __init__(self, num_classes, num_sparseblk_count, depth, reduction=.5, droprate=0.0, growth_rate=12, \n",
    "                 bottleneck=False, verbose=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope(): \n",
    "            net = self.net = gluon.nn.HybridSequential() # 整合之后的网络\n",
    "            \n",
    "            # 每个SpraseBlock有多少个block\n",
    "            nDenseBlock = (depth - 4) // num_sparseblk_count\n",
    "            # 如果是bottleneck，那么每个nDenseBlock减半，因为每个bottleneck中有两个Conv2D\n",
    "            if bottleneck:\n",
    "                nDenseBlock //= 2\n",
    "            else:\n",
    "                reduction = 1\n",
    "            \n",
    "            # Init Conv Layer\n",
    "            init_channels = growth_rate\n",
    "            net.add(gluon.nn.Conv2D(init_channels, kernel_size=3, padding=1))\n",
    "            \n",
    "            # Sparse Connected Layer\n",
    "            sparse_output_channel = init_channels\n",
    "            for idx in range(num_sparseblk_count):\n",
    "                b2 = gluon.nn.HybridSequential()\n",
    "                \n",
    "                # Adding SparseBlock\n",
    "                b2.add(SparseBlock(nDenseBlock, growth_rate, bottleneck))\n",
    "                \n",
    "                # 统计每个sparseblock的输出通道数 用于给过渡层以固定的reduction比例减少通道数\n",
    "                sparse_output_filter = [sparse_output_channel]\n",
    "                for _ in range(nDenseBlock):\n",
    "                    sparse_output_filter.append(growth_rate)\n",
    "                sparse_output_channel = sum(fetch_exponential_idx(sparse_output_filter)) * reduction\n",
    "                \n",
    "                # 过渡层比SparseBlock层少一层 \n",
    "                if idx != num_sparseblk_count - 1:\n",
    "                    # Transition Layer 每次过渡层将输出通道减半\n",
    "                    b2.add(TransitionLayer(int(sparse_output_channel), droprate))\n",
    "                net.add(b2)\n",
    "            \n",
    "            ############# final feature layer\n",
    "            net.add(gluon.nn.BatchNorm(axis=1))\n",
    "            net.add(gluon.nn.Activation('relu'))\n",
    "            #############        \n",
    "            \n",
    "            # Classification Layer\n",
    "            b3 = gluon.nn.HybridSequential()\n",
    "            b3.add(\n",
    "                gluon.nn.GlobalAvgPool2D(),\n",
    "                gluon.nn.Dense(num_classes)\n",
    "            )\n",
    "            net.add(b3)\n",
    "            \n",
    "    def hybrid_forward(self, F, X):\n",
    "        out = X\n",
    "        for i, blk in enumerate(self.net):\n",
    "            out = blk(out)\n",
    "            if self.verbose:\n",
    "                print(\"blk %d : %s\" % (i+1, out.shape))\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用``gluon``开始批量归一化\n",
    "\n",
    "使用``gluon``实现批量归一化则简单得多，我们只需要像``Dense``层那样指定``gluon.nn.BatchNorm``层，并指定对二维卷积的通道层(axis=1)做归一化即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T12:23:17.237492Z",
     "start_time": "2018-01-21T12:23:16.703159Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "ctx = mx.gpu()\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T12:23:17.559949Z",
     "start_time": "2018-01-21T12:23:17.240452Z"
    }
   },
   "outputs": [],
   "source": [
    "num_examples = 60000\n",
    "num_input = 784\n",
    "num_output = 10\n",
    "\n",
    "batch_size = 64\n",
    "train_data, test_data = utils.load_dataset(batch_size, data_type='mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T12:23:17.579537Z",
     "start_time": "2018-01-21T12:23:17.561357Z"
    }
   },
   "outputs": [],
   "source": [
    "num_output_conv1 = 20\n",
    "num_output_conv2 = 50\n",
    "num_output_fc1 = 128\n",
    "num_output_fc2 = 10\n",
    "\n",
    "def get_net():\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        # first conv layer\n",
    "        net.add(gluon.nn.Conv2D(num_output_conv1, kernel_size=3, activation=\"relu\"))\n",
    "        net.add(gluon.nn.BatchNorm(axis=1))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "        # second conv layer \n",
    "        net.add(gluon.nn.Conv2D(num_output_conv2, kernel_size=3, activation=\"relu\"))\n",
    "        net.add(gluon.nn.BatchNorm(axis=1))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "        # flatten layer \n",
    "        net.add(gluon.nn.Flatten())\n",
    "        # first fc layer \n",
    "        net.add(gluon.nn.Dense(num_output_fc1, activation=\"relu\"))\n",
    "        # output layer \n",
    "        net.add(gluon.nn.Dense(num_output_fc2))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T12:23:18.379994Z",
     "start_time": "2018-01-21T12:23:17.580624Z"
    }
   },
   "outputs": [],
   "source": [
    "net = get_net()\n",
    "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T12:23:18.389207Z",
     "start_time": "2018-01-21T12:23:18.381334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter sequential0_conv0_weight (shape=(20, 0, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv0_bias (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm0_gamma (shape=(0,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm0_beta (shape=(0,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm0_running_mean (shape=(0,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm0_running_var (shape=(0,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv1_weight (shape=(50, 0, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv1_bias (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm1_gamma (shape=(0,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm1_beta (shape=(0,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm1_running_mean (shape=(0,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm1_running_var (shape=(0,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense0_weight (shape=(128, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense0_bias (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense1_weight (shape=(10, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense1_bias (shape=(10,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T12:23:18.651766Z",
     "start_time": "2018-01-21T12:23:18.390336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data, _ in train_data:\n",
    "    data = data.as_in_context(ctx)\n",
    "    print(data.shape)\n",
    "    break\n",
    "    \n",
    "net(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T12:23:18.657277Z",
     "start_time": "2018-01-21T12:23:18.653051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter sequential0_conv0_weight (shape=(20, 1, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv0_bias (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm0_gamma (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm0_beta (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm0_running_mean (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm0_running_var (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv1_weight (shape=(50, 20, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_conv1_bias (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm1_gamma (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm1_beta (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm1_running_mean (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_batchnorm1_running_var (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense0_weight (shape=(128, 1250), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense0_bias (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense1_weight (shape=(10, 128), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential0_dense1_bias (shape=(10,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T12:27:36.183350Z",
     "start_time": "2018-01-21T12:23:18.658400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Moving Train Avg loss 0.09402, Train acc 0.97982, Test acc 0.97920, Time consume 25.92356 s.\n",
      "Epoch 1, Moving Train Avg loss 0.05288, Train acc 0.98732, Test acc 0.98330, Time consume 25.94563 s.\n",
      "Epoch 2, Moving Train Avg loss 0.03899, Train acc 0.98990, Test acc 0.98530, Time consume 25.91965 s.\n",
      "Epoch 3, Moving Train Avg loss 0.03017, Train acc 0.99283, Test acc 0.98690, Time consume 25.87799 s.\n",
      "Epoch 4, Moving Train Avg loss 0.02555, Train acc 0.99440, Test acc 0.98750, Time consume 25.81163 s.\n",
      "Epoch 5, Moving Train Avg loss 0.02323, Train acc 0.99482, Test acc 0.98750, Time consume 25.89330 s.\n",
      "Epoch 6, Moving Train Avg loss 0.01272, Train acc 0.99588, Test acc 0.98830, Time consume 25.80154 s.\n",
      "Epoch 7, Moving Train Avg loss 0.01490, Train acc 0.99663, Test acc 0.98850, Time consume 25.52007 s.\n",
      "Epoch 8, Moving Train Avg loss 0.01256, Train acc 0.99752, Test acc 0.98900, Time consume 25.39434 s.\n",
      "Epoch 9, Moving Train Avg loss 0.01898, Train acc 0.99715, Test acc 0.98820, Time consume 25.41225 s.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate' : learning_rate})\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "niter = 0\n",
    "moving_loss = 0.0\n",
    "smoothing_constant = 0.9\n",
    "\n",
    "from time import time\n",
    "for epoch in range(epochs):\n",
    "    start = time()\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "        \n",
    "        niter += 1\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = smoothing_constant * moving_loss + (1-smoothing_constant) * curr_loss\n",
    "        estimated_loss = moving_loss / (1 - smoothing_constant**niter)\n",
    "    \n",
    "    train_acc = utils.evaluate_accuracy_gluon(train_data, net, ctx)\n",
    "    test_acc = utils.evaluate_accuracy_gluon(test_data, net, ctx)\n",
    "    print(\"Epoch %d, Moving Train Avg loss %.5f, Train acc %.5f, Test acc %.5f, Time consume %.5f s.\"\n",
    "         % (epoch, estimated_loss, train_acc, test_acc, time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度卷积生成对抗网络\n",
    "\n",
    "论文地址：https://arxiv.org/abs/1511.06434\n",
    "\n",
    "在之前我们看到了如何用GAN来生成服从一个分布的假样本，即将它们转换成与某些数据集的分布相匹配的样本。\n",
    "\n",
    "那么很自然地，深度卷积网络拥有更强大地判别能力，因此，在本章中，我们将讨论深度卷积网络的生成对抗网络，深度卷积网络已经被成功的应用于计算机视觉之中，因此，在本章中，我们将CNN结合GAN，来生成逼真的图片。\n",
    "\n",
    "我们使用的数据集是LWF人脸数据集：http://vis-www.cs.umass.edu/lfw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:08:18.704666Z",
     "start_time": "2018-04-16T09:08:12.962182Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import autograd\n",
    "\n",
    "%matplotlib inline\n",
    "import tarfile\n",
    "import matplotlib as mlt\n",
    "mlt.rcParams['figure.dpi'] = 120\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:49:33.094670Z",
     "start_time": "2018-04-16T10:49:33.087957Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 64\n",
    "latent_z_size = 100\n",
    "\n",
    "use_gpu = True\n",
    "ctx = mx.gpu() if use_gpu else mx.cpu()\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:49:36.142463Z",
     "start_time": "2018-04-16T10:49:36.079445Z"
    }
   },
   "outputs": [],
   "source": [
    "lfw_url = 'http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz'\n",
    "data_path = '../data/lfw_dataset/lfw-deepfunneled'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    data_file = gluon.utils.download(lfw_url)\n",
    "    with tarfile.open(data_file) as tar:\n",
    "        tar.extractall(path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:49:38.614081Z",
     "start_time": "2018-04-16T10:49:38.601601Z"
    }
   },
   "outputs": [],
   "source": [
    "target_wd = 64\n",
    "target_ht = 64\n",
    "img_list = []\n",
    "\n",
    "def transform(data, target_wd, target_ht):\n",
    "    data = image.imresize(data, target_wd, target_ht)\n",
    "    data = nd.transpose(data, (2, 0, 1)) # channel X height X width\n",
    "    # normalize to [-1, 1]\n",
    "    data = data.astype(np.float32) / 127.5 - 1\n",
    "    # if img is greyscale, repeat 3 times to get RGB img\n",
    "    if data.shape[0] == 1:\n",
    "        data = nd.tile(data, (3,1,1))\n",
    "    return data.reshape((1,) + data.shape) # reshape to (1,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, _, fnames in os.walk(data_path):\n",
    "    for fname in fnames:\n",
    "        if not fname.endswith('.jpg'):\n",
    "            continue\n",
    "        img = os.path.join(path, fname)\n",
    "        img_arr = image.imread(img)\n",
    "        img_arr = transform(img_arr, target_wd, target_ht)\n",
    "        img_list.append(img_arr)\n",
    "        \n",
    "train_data = mx.io.NDArrayIter(data=nd.concatenate(img_list), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img_arr):\n",
    "    plt.imshow((img_arr.asnumpy().transpose((1, 2, 0)) + 1.0) * 127.5).astype(np.uint8)\n",
    "    plt.axis('off')\n",
    "    \n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    visualize(img_list[i + 10][0])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN\n",
    "\n",
    "DCGAN使用标准的CNN结构构建判别模型。对生成模型来说，卷积层被上卷积层所取代，所以每层的表示实际上都在相继变大，DCGAN的特点如下：\n",
    "\n",
    "\n",
    "* Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "* Use batch normalization in both the generator and the discriminator.\n",
    "* Remove fully connected hidden layers for deeper architectures.\n",
    "* Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "* Use LeakyReLU activation in the discriminator for all layers.\n",
    "\n",
    "<img src=\"http://gluon.mxnet.io/_images/dcgan.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:33:31.017597Z",
     "start_time": "2018-04-16T10:33:30.974394Z"
    }
   },
   "outputs": [],
   "source": [
    "nc = 3\n",
    "ngf = 64\n",
    "generator = gluon.nn.Sequential()\n",
    "with generator.name_scope():\n",
    "    # input Z, going into a convolution\n",
    "    generator.add(gluon.nn.Conv2DTranspose(channels=8 * ngf, kernel_size=4, strides=1, padding=0, use_bias=False))\n",
    "    generator.add(gluon.nn.BatchNorm(axis=1))\n",
    "    generator.add(gluon.nn.Activation('relu'))\n",
    "    # output size (nfg*8) X 4 X 4\n",
    "    generator.add(gluon.nn.Conv2DTranspose(channels=4 * ngf, kernel_size=4, strides=2, padding=1, use_bias=False))\n",
    "    generator.add(gluon.nn.BatchNorm(axis=1))\n",
    "    generator.add(gluon.nn.Activation('relu'))\n",
    "    # output size (nfg*8) X 8 X 8\n",
    "    generator.add(gluon.nn.Conv2DTranspose(channels=2 * ngf, kernel_size=4, strides=2, padding=1, use_bias=False))\n",
    "    generator.add(gluon.nn.BatchNorm(axis=1))\n",
    "    generator.add(gluon.nn.Activation('relu'))\n",
    "    # output size (nfg*8) X 16 X 16\n",
    "    generator.add(gluon.nn.Conv2DTranspose(channels=ngf, kernel_size=4, strides=2, padding=1, use_bias=False))\n",
    "    generator.add(gluon.nn.BatchNorm(axis=1))\n",
    "    generator.add(gluon.nn.Activation('relu'))\n",
    "    # output size (nfg*8) X 32 X 32\n",
    "    generator.add(gluon.nn.Conv2DTranspose(channels=nc, kernel_size=4, strides=2, padding=1, use_bias=False))\n",
    "    generator.add(gluon.nn.Activation('tanh'))\n",
    "    # output size (nc) X 64 X 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:33:31.735243Z",
     "start_time": "2018-04-16T10:33:31.702017Z"
    }
   },
   "outputs": [],
   "source": [
    "ndf = 64\n",
    "discriminator = gluon.nn.Sequential()\n",
    "with discriminator.name_scope():\n",
    "    # input size (nc) X 64 X 64\n",
    "    discriminator.add(gluon.nn.Conv2D(channels=ndf, kernel_size=4, strides=2, padding=1, use_bias=False))\n",
    "    discriminator.add(gluon.nn.LeakyReLU(0.2))\n",
    "    # output size (ndf) * 32 * 32\n",
    "    discriminator.add(gluon.nn.Conv2D(channels=2 * ndf, kernel_size=4, strides=2, padding=1, use_bias=False))\n",
    "    discriminator.add(gluon.nn.BatchNorm(axis=1))\n",
    "    discriminator.add(gluon.nn.LeakyReLU(0.2))\n",
    "    # output size (ndf*2) * 16 * 16\n",
    "    discriminator.add(gluon.nn.Conv2D(channels=4 * ndf, kernel_size=4, strides=2, padding=1, use_bias=False))\n",
    "    discriminator.add(gluon.nn.BatchNorm(axis=1))\n",
    "    discriminator.add(gluon.nn.LeakyReLU(0.2))    \n",
    "    # output size (ndf*4) * 8 * 8\n",
    "    discriminator.add(gluon.nn.Conv2D(channels=8 * ndf, kernel_size=4, strides=2, padding=1, use_bias=False))\n",
    "    discriminator.add(gluon.nn.BatchNorm(axis=1))\n",
    "    discriminator.add(gluon.nn.LeakyReLU(0.2))    \n",
    "    # output size (ndf*8) * 4 * 4\n",
    "    discriminator.add(gluon.nn.Conv2D(channels=1, kernel_size=4, strides=1, padding=0, use_bias=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:50:52.886495Z",
     "start_time": "2018-04-16T10:50:52.873759Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "generator.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "discriminator.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "\n",
    "trainerG = gluon.Trainer(generator.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1})\n",
    "trainerD = gluon.Trainer(discriminator.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "\n",
    "real_label = nd.ones((batch_size, ), ctx=ctx)\n",
    "fake_label = nd.zeros((batch_size, ), ctx=ctx)\n",
    "\n",
    "def facc(label, pred):\n",
    "    pred = pred.ravel() # Return a contiguous flattened array.\n",
    "    label = pred.revel() # Return a contiguous flattened array.\n",
    "    return ((pred > 0.5) == label).mean()\n",
    "\n",
    "metric = mx.metric.CustomMetric(facc)\n",
    "\n",
    "stamp = datetime.now().strftime(\"%Y_%m_%d-%H_%M\")\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    btic = time.time()\n",
    "    train_data.reset()\n",
    "    iter = 0\n",
    "    for batch in train_data:\n",
    "        ####################################################\n",
    "        # (1) Update D network : maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ####################################################\n",
    "        data = batch.data[0].as_in_context(ctx)\n",
    "        latent_z = nd.random.normal(0, 1, shape=(batch_size, latent_z_size, 1, 1), ctx=ctx) # noise\n",
    "        \n",
    "        with autograd.record():\n",
    "            real_output = discriminator(data).reshape((-1, 1))\n",
    "            err_discrim_real = loss(real_output, real_label)\n",
    "            metric.update([real_label,], [real_output,]) #\n",
    "            \n",
    "            fake = generator(noise)\n",
    "            fake_output = discriminator(fake.detach()).reshape((-1,1))\n",
    "            err_discrim_fake = loss(fake_output, fake_label)\n",
    "            \n",
    "            err_discrim = err_discrim_fake + err_discrim_real\n",
    "            err_discrim.backward()\n",
    "            metric.update([fake_label,], [fake_output,]) # \n",
    "            \n",
    "        trainerD.step(batch.data[0].shape[0])\n",
    "\n",
    "        ####################################################\n",
    "        # (1) Update G network : maximize log(D(G(z)))\n",
    "        ####################################################\n",
    "        with autograd.record():\n",
    "            fake = generator(latent_z)\n",
    "            output = discriminator(fake).reshape((-1,1))\n",
    "            err_generator = loss(output, real_label)\n",
    "            err_generator.backward()\n",
    "            \n",
    "        trainerG.step(batch.data[0].shape[0])\n",
    "        \n",
    "        if iter % 10 == 0:\n",
    "            name, acc = metric.get()\n",
    "            logging.info('speed: {} samples/s'.format(batch_size / (time.time() - btic)))\n",
    "            logging.info('discriminator loss = %f, generator loss = %f, binary training acc = %f at iter %d epoch %d'\n",
    "                     %(nd.mean(errD).asscalar(),\n",
    "                       nd.mean(errG).asscalar(), acc, iter, epoch))\n",
    "    \n",
    "        iter = iter + 1\n",
    "        btic = time.time()\n",
    "        \n",
    "    name, acc = metric.get()\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试\n",
    "\n",
    "给定一个生成器，我们可以生成一些关于脸的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 8\n",
    "\n",
    "for i in range(num_image):\n",
    "    latent_z = nd.random.normal(0, 1, shape=(1, latent_z_size, 1, 1), ctx=ctx)\n",
    "    img = generator(latent_z)\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    visualize(img[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
